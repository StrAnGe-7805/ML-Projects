{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(date):\n",
    "    papi = [datetime(int(i[:4]),int(i[5:7]),int(i[8:10]),int(i[11:13]),int(i[14:16]),int(i[17:19])) for i in date]\n",
    "    papi = [(i - min(papi)).total_seconds() for i in papi]\n",
    "    papi = [i/max(papi) for i in papi]\n",
    "    return papi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['instock_date'] = get_date(df['instock_date'].values)\n",
    "df['stock_update_date'] = get_date(df['stock_update_date'].values)\n",
    "df['uk_date1'] = get_date(df['uk_date1'].values)\n",
    "df['uk_date2'] = get_date(df['uk_date2'].values)\n",
    "df_test['instock_date'] = get_date(df_test['instock_date'].values)\n",
    "df_test['stock_update_date'] = get_date(df_test['stock_update_date'].values)\n",
    "df_test['uk_date1'] = get_date(df_test['uk_date1'].values)\n",
    "df_test['uk_date2'] = get_date(df_test['uk_date2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['volumes'].fillna(1, inplace=True)\n",
    "df_test['volumes'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.iloc[:-1000,1:-1].values\n",
    "y_train = df.iloc[:-1000,-1].values\n",
    "x_train_test = df.iloc[-1000:,1:-1].values\n",
    "y_train_test = df.iloc[-1000:,-1].values\n",
    "x_test = df_test.iloc[:,1:].values\n",
    "ids = df_test.iloc[:,0]\n",
    "\n",
    "x_train_w = []\n",
    "y_train_w = []\n",
    "x_train_test_w = []\n",
    "y_train_test_w = []\n",
    "\n",
    "x_train_o = []\n",
    "y_train_o = []\n",
    "x_train_test_o = []\n",
    "y_train_test_o = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    if(x_train[i][-1] == 1):\n",
    "        x_train_o.append(x_train[i][:-1])\n",
    "        y_train_o.append(y_train[i])\n",
    "    else:\n",
    "        x_train_w.append(x_train[i])\n",
    "        y_train_w.append(y_train[i])\n",
    "\n",
    "for i in range(len(x_train_test)):\n",
    "    if(x_train_test[i][-1] == 1):\n",
    "        x_train_test_o.append(x_train_test[i][:-1])\n",
    "        y_train_test_o.append(y_train_test[i])\n",
    "    else:\n",
    "        x_train_test_w.append(x_train_test[i])\n",
    "        y_train_test_w.append(y_train_test[i])\n",
    "\n",
    "x_train_w = np.array(x_train_w)\n",
    "x_train_o = np.array(x_train_o)\n",
    "y_train_w = np.array(y_train_w)\n",
    "y_train_o = np.array(y_train_o)\n",
    "x_train_test_w = np.array(x_train_test_w)\n",
    "x_train_test_o = np.array(x_train_test_o)\n",
    "y_train_test_w = np.array(y_train_test_w)\n",
    "y_train_test_o = np.array(y_train_test_o)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_w = StandardScaler()\n",
    "x_train_w = sc_w.fit_transform(x_train_w)\n",
    "x_train_test_w = sc_w.transform(x_train_test_w)\n",
    "\n",
    "sc_o = StandardScaler()\n",
    "x_train_o = sc_o.fit_transform(x_train_o)\n",
    "x_train_test_o = sc_o.transform(x_train_test_o)\n",
    "\n",
    "# print(len(x_train_test_o))\n",
    "# print(len(x_train_test_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ".3704e-04\nEpoch 26/100\n7297/7297 [==============================] - 1s 91us/step - loss: 978.8297 - accuracy: 1.3704e-04\nEpoch 27/100\n7297/7297 [==============================] - 1s 92us/step - loss: 962.6457 - accuracy: 1.3704e-04\nEpoch 28/100\n7297/7297 [==============================] - 1s 94us/step - loss: 947.9991 - accuracy: 2.7409e-04\nEpoch 29/100\n7297/7297 [==============================] - 1s 97us/step - loss: 935.6261 - accuracy: 0.0000e+00\nEpoch 30/100\n7297/7297 [==============================] - 0s 66us/step - loss: 904.5693 - accuracy: 1.3704e-04\nEpoch 31/100\n7297/7297 [==============================] - 0s 67us/step - loss: 878.4115 - accuracy: 2.7409e-04\nEpoch 32/100\n7297/7297 [==============================] - 1s 72us/step - loss: 1085.6784 - accuracy: 4.1113e-04\nEpoch 33/100\n7297/7297 [==============================] - 1s 100us/step - loss: 863.1693 - accuracy: 1.3704e-04\nEpoch 34/100\n7297/7297 [==============================] - 1s 100us/step - loss: 844.2971 - accuracy: 0.0000e+00\nEpoch 35/100\n7297/7297 [==============================] - 1s 105us/step - loss: 827.2257 - accuracy: 1.3704e-04\nEpoch 36/100\n7297/7297 [==============================] - 1s 93us/step - loss: 828.3388 - accuracy: 2.7409e-04\nEpoch 37/100\n7297/7297 [==============================] - 1s 92us/step - loss: 811.9071 - accuracy: 0.0000e+00\nEpoch 38/100\n7297/7297 [==============================] - 1s 106us/step - loss: 803.2688 - accuracy: 1.3704e-04\nEpoch 39/100\n7297/7297 [==============================] - 1s 98us/step - loss: 798.5747 - accuracy: 2.7409e-04\nEpoch 40/100\n7297/7297 [==============================] - 1s 112us/step - loss: 777.6296 - accuracy: 2.7409e-04\nEpoch 41/100\n7297/7297 [==============================] - 1s 92us/step - loss: 765.4506 - accuracy: 4.1113e-04\nEpoch 42/100\n7297/7297 [==============================] - 1s 83us/step - loss: 751.6120 - accuracy: 4.1113e-04\nEpoch 43/100\n7297/7297 [==============================] - 0s 62us/step - loss: 741.2551 - accuracy: 1.3704e-04\nEpoch 44/100\n7297/7297 [==============================] - 0s 68us/step - loss: 734.6278 - accuracy: 2.7409e-04\nEpoch 45/100\n7297/7297 [==============================] - 1s 102us/step - loss: 842.2878 - accuracy: 1.3704e-04\nEpoch 46/100\n7297/7297 [==============================] - 1s 92us/step - loss: 705.3676 - accuracy: 0.0000e+00\nEpoch 47/100\n7297/7297 [==============================] - 1s 105us/step - loss: 698.3434 - accuracy: 1.3704e-04\nEpoch 48/100\n7297/7297 [==============================] - 1s 96us/step - loss: 716.3309 - accuracy: 1.3704e-04\nEpoch 49/100\n7297/7297 [==============================] - 1s 95us/step - loss: 689.1662 - accuracy: 2.7409e-04\nEpoch 50/100\n7297/7297 [==============================] - 1s 97us/step - loss: 673.4135 - accuracy: 6.8521e-04\nEpoch 51/100\n7297/7297 [==============================] - 1s 96us/step - loss: 664.3669 - accuracy: 2.7409e-04\nEpoch 52/100\n7297/7297 [==============================] - 1s 91us/step - loss: 667.3691 - accuracy: 2.7409e-04\nEpoch 53/100\n7297/7297 [==============================] - 1s 98us/step - loss: 652.9587 - accuracy: 1.3704e-04\nEpoch 54/100\n7297/7297 [==============================] - 1s 89us/step - loss: 630.5704 - accuracy: 0.0000e+00\nEpoch 55/100\n7297/7297 [==============================] - 0s 65us/step - loss: 630.5051 - accuracy: 5.4817e-04\nEpoch 56/100\n7297/7297 [==============================] - 0s 63us/step - loss: 630.7294 - accuracy: 5.4817e-04\nEpoch 57/100\n7297/7297 [==============================] - 1s 91us/step - loss: 603.3504 - accuracy: 2.7409e-04\nEpoch 58/100\n7297/7297 [==============================] - 1s 96us/step - loss: 601.8450 - accuracy: 5.4817e-04\nEpoch 59/100\n7297/7297 [==============================] - 1s 95us/step - loss: 603.5041 - accuracy: 4.1113e-04\nEpoch 60/100\n7297/7297 [==============================] - 1s 101us/step - loss: 576.6701 - accuracy: 2.7409e-04\nEpoch 61/100\n7297/7297 [==============================] - 1s 104us/step - loss: 589.7692 - accuracy: 5.4817e-04\nEpoch 62/100\n7297/7297 [==============================] - 1s 93us/step - loss: 593.4022 - accuracy: 6.8521e-04\nEpoch 63/100\n7297/7297 [==============================] - 1s 94us/step - loss: 572.4619 - accuracy: 4.1113e-04\nEpoch 64/100\n7297/7297 [==============================] - 1s 98us/step - loss: 560.3086 - accuracy: 0.0000e+00\nEpoch 65/100\n7297/7297 [==============================] - 1s 100us/step - loss: 544.5302 - accuracy: 1.3704e-04\nEpoch 66/100\n7297/7297 [==============================] - 1s 94us/step - loss: 545.2415 - accuracy: 4.1113e-04\nEpoch 67/100\n7297/7297 [==============================] - 0s 63us/step - loss: 542.8263 - accuracy: 2.7409e-04\nEpoch 68/100\n7297/7297 [==============================] - 0s 65us/step - loss: 548.0464 - accuracy: 1.3704e-04\nEpoch 69/100\n7297/7297 [==============================] - 1s 82us/step - loss: 528.8421 - accuracy: 2.7409e-04\nEpoch 70/100\n7297/7297 [==============================] - 1s 104us/step - loss: 503.9428 - accuracy: 4.1113e-04\nEpoch 71/100\n7297/7297 [==============================] - 1s 94us/step - loss: 510.3121 - accuracy: 0.0000e+00\nEpoch 72/100\n7297/7297 [==============================] - 1s 103us/step - loss: 527.8244 - accuracy: 4.1113e-04\nEpoch 73/100\n7297/7297 [==============================] - 1s 95us/step - loss: 500.5510 - accuracy: 1.3704e-04\nEpoch 74/100\n7297/7297 [==============================] - 1s 121us/step - loss: 497.4569 - accuracy: 6.8521e-04\nEpoch 75/100\n7297/7297 [==============================] - 1s 160us/step - loss: 493.4959 - accuracy: 1.3704e-04\nEpoch 76/100\n7297/7297 [==============================] - 1s 142us/step - loss: 513.3418 - accuracy: 0.0000e+00\nEpoch 77/100\n7297/7297 [==============================] - 1s 126us/step - loss: 471.2003 - accuracy: 2.7409e-04\nEpoch 78/100\n7297/7297 [==============================] - 1s 97us/step - loss: 476.9959 - accuracy: 2.7409e-04\nEpoch 79/100\n7297/7297 [==============================] - 1s 105us/step - loss: 465.1735 - accuracy: 2.7409e-04\nEpoch 80/100\n7297/7297 [==============================] - 1s 72us/step - loss: 460.8112 - accuracy: 1.3704e-04\nEpoch 81/100\n7297/7297 [==============================] - 1s 81us/step - loss: 467.4841 - accuracy: 2.7409e-04\nEpoch 82/100\n7297/7297 [==============================] - 1s 106us/step - loss: 455.8250 - accuracy: 1.3704e-04\nEpoch 83/100\n7297/7297 [==============================] - 1s 105us/step - loss: 444.8448 - accuracy: 4.1113e-04\nEpoch 84/100\n7297/7297 [==============================] - 1s 99us/step - loss: 461.3071 - accuracy: 2.7409e-04\nEpoch 85/100\n7297/7297 [==============================] - 1s 104us/step - loss: 450.6768 - accuracy: 2.7409e-04\nEpoch 86/100\n7297/7297 [==============================] - 1s 102us/step - loss: 452.7784 - accuracy: 2.7409e-04\nEpoch 87/100\n7297/7297 [==============================] - 1s 100us/step - loss: 431.6513 - accuracy: 1.3704e-04\nEpoch 88/100\n7297/7297 [==============================] - 1s 96us/step - loss: 441.8692 - accuracy: 0.0000e+00\nEpoch 89/100\n7297/7297 [==============================] - 1s 96us/step - loss: 449.5304 - accuracy: 4.1113e-04\nEpoch 90/100\n7297/7297 [==============================] - 1s 107us/step - loss: 417.0926 - accuracy: 2.7409e-04\nEpoch 91/100\n7297/7297 [==============================] - 1s 76us/step - loss: 416.6501 - accuracy: 1.3704e-04\nEpoch 92/100\n7297/7297 [==============================] - 0s 66us/step - loss: 413.9803 - accuracy: 5.4817e-04\nEpoch 93/100\n7297/7297 [==============================] - 1s 74us/step - loss: 430.4441 - accuracy: 4.1113e-04\nEpoch 94/100\n7297/7297 [==============================] - 1s 106us/step - loss: 430.2429 - accuracy: 0.0000e+00\nEpoch 95/100\n7297/7297 [==============================] - 1s 109us/step - loss: 396.7551 - accuracy: 0.0000e+00\nEpoch 96/100\n7297/7297 [==============================] - 1s 93us/step - loss: 409.1098 - accuracy: 5.4817e-04\nEpoch 97/100\n7297/7297 [==============================] - 1s 101us/step - loss: 396.5088 - accuracy: 2.7409e-04\nEpoch 98/100\n7297/7297 [==============================] - 1s 99us/step - loss: 390.6374 - accuracy: 4.1113e-04\nEpoch 99/100\n7297/7297 [==============================] - 1s 96us/step - loss: 388.1507 - accuracy: 0.0000e+00\nEpoch 100/100\n7297/7297 [==============================] - 1s 96us/step - loss: 396.5979 - accuracy: 1.3704e-04\n26/26 [==============================] - 0s 2ms/step\nEpoch 1/100\n11982/11982 [==============================] - 1s 91us/step - loss: 71792.2419 - accuracy: 8.3459e-05\nEpoch 2/100\n11982/11982 [==============================] - 1s 85us/step - loss: 54846.8663 - accuracy: 8.3459e-05\nEpoch 3/100\n11982/11982 [==============================] - 1s 96us/step - loss: 53671.0217 - accuracy: 1.6692e-04\nEpoch 4/100\n11982/11982 [==============================] - 1s 104us/step - loss: 52889.8686 - accuracy: 1.6692e-04\nEpoch 5/100\n11982/11982 [==============================] - 1s 91us/step - loss: 52181.3910 - accuracy: 0.0000e+00\nEpoch 6/100\n11982/11982 [==============================] - 1s 92us/step - loss: 51575.9159 - accuracy: 1.6692e-04\nEpoch 7/100\n11982/11982 [==============================] - 1s 96us/step - loss: 50883.0384 - accuracy: 0.0000e+00\nEpoch 8/100\n11982/11982 [==============================] - 1s 84us/step - loss: 50480.9334 - accuracy: 1.6692e-04\nEpoch 9/100\n11982/11982 [==============================] - 1s 65us/step - loss: 50013.3770 - accuracy: 8.3459e-05\nEpoch 10/100\n11982/11982 [==============================] - 1s 101us/step - loss: 49684.8207 - accuracy: 0.0000e+00\nEpoch 11/100\n11982/11982 [==============================] - 1s 93us/step - loss: 49327.0396 - accuracy: 0.0000e+00\nEpoch 12/100\n11982/11982 [==============================] - 1s 96us/step - loss: 49119.5373 - accuracy: 0.0000e+00\nEpoch 13/100\n11982/11982 [==============================] - 1s 92us/step - loss: 49108.1810 - accuracy: 8.3459e-05\nEpoch 14/100\n11982/11982 [==============================] - 1s 98us/step - loss: 49229.9117 - accuracy: 8.3459e-05\nEpoch 15/100\n11982/11982 [==============================] - 1s 91us/step - loss: 48644.4633 - accuracy: 0.0000e+00\nEpoch 16/100\n11982/11982 [==============================] - 1s 77us/step - loss: 48446.5847 - accuracy: 1.6692e-04\nEpoch 17/100\n11982/11982 [==============================] - 1s 78us/step - loss: 48142.2138 - accuracy: 8.3459e-05\nEpoch 18/100\n11982/11982 [==============================] - 1s 94us/step - loss: 48134.9157 - accuracy: 0.0000e+00\nEpoch 19/100\n11982/11982 [==============================] - 1s 100us/step - loss: 47843.4879 - accuracy: 8.3459e-05\nEpoch 20/100\n11982/11982 [==============================] - 1s 103us/step - loss: 47637.9902 - accuracy: 8.3459e-05\nEpoch 21/100\n11982/11982 [==============================] - 1s 95us/step - loss: 47544.4075 - accuracy: 0.0000e+00\nEpoch 22/100\n11982/11982 [==============================] - 1s 100us/step - loss: 46919.8345 - accuracy: 1.6692e-04\nEpoch 23/100\n11982/11982 [==============================] - 1s 86us/step - loss: 46618.6307 - accuracy: 0.0000e+00\nEpoch 24/100\n11982/11982 [==============================] - 1s 65us/step - loss: 46259.2881 - accuracy: 2.5038e-04\nEpoch 25/100\n11982/11982 [==============================] - 1s 101us/step - loss: 45840.5877 - accuracy: 0.0000e+00\nEpoch 26/100\n11982/11982 [==============================] - 1s 95us/step - loss: 45593.2027 - accuracy: 0.0000e+00\nEpoch 27/100\n11982/11982 [==============================] - 1s 104us/step - loss: 45187.0550 - accuracy: 8.3459e-05\nEpoch 28/100\n11982/11982 [==============================] - 1s 94us/step - loss: 44681.2626 - accuracy: 0.0000e+00\nEpoch 29/100\n11982/11982 [==============================] - 1s 91us/step - loss: 44660.3036 - accuracy: 0.0000e+00\nEpoch 30/100\n11982/11982 [==============================] - 1s 97us/step - loss: 43776.7764 - accuracy: 0.0000e+00\nEpoch 31/100\n11982/11982 [==============================] - 1s 70us/step - loss: 43802.1798 - accuracy: 8.3459e-05\nEpoch 32/100\n11982/11982 [==============================] - 1s 90us/step - loss: 42774.6968 - accuracy: 0.0000e+00\nEpoch 33/100\n11982/11982 [==============================] - 1s 99us/step - loss: 41938.6150 - accuracy: 0.0000e+00\nEpoch 34/100\n11982/11982 [==============================] - 1s 102us/step - loss: 41731.1365 - accuracy: 8.3459e-05\nEpoch 35/100\n11982/11982 [==============================] - 1s 108us/step - loss: 40660.0172 - accuracy: 0.0000e+00\nEpoch 36/100\n11982/11982 [==============================] - 1s 94us/step - loss: 39606.7344 - accuracy: 8.3459e-05\nEpoch 37/100\n11982/11982 [==============================] - 1s 95us/step - loss: 39713.4001 - accuracy: 8.3459e-05\nEpoch 38/100\n11982/11982 [==============================] - 1s 77us/step - loss: 39311.5005 - accuracy: 1.6692e-04\nEpoch 39/100\n11982/11982 [==============================] - 1s 69us/step - loss: 37532.1240 - accuracy: 0.0000e+00\nEpoch 40/100\n11982/11982 [==============================] - 1s 102us/step - loss: 37201.9293 - accuracy: 8.3459e-05\nEpoch 41/100\n11982/11982 [==============================] - 1s 104us/step - loss: 36379.4226 - accuracy: 1.6692e-04\nEpoch 42/100\n11982/11982 [==============================] - 1s 104us/step - loss: 35476.2237 - accuracy: 1.6692e-04\nEpoch 43/100\n11982/11982 [==============================] - 1s 104us/step - loss: 34961.2815 - accuracy: 0.0000e+00\nEpoch 44/100\n11982/11982 [==============================] - 1s 95us/step - loss: 33768.7084 - accuracy: 8.3459e-05\nEpoch 45/100\n11982/11982 [==============================] - 1s 84us/step - loss: 33522.6934 - accuracy: 8.3459e-05\nEpoch 46/100\n11982/11982 [==============================] - 1s 61us/step - loss: 32724.2275 - accuracy: 2.5038e-04\nEpoch 47/100\n11982/11982 [==============================] - 1s 87us/step - loss: 31540.4945 - accuracy: 8.3459e-05\nEpoch 48/100\n11982/11982 [==============================] - 1s 100us/step - loss: 31048.8915 - accuracy: 0.0000e+00\nEpoch 49/100\n11982/11982 [==============================] - 1s 98us/step - loss: 29501.7996 - accuracy: 8.3459e-05\nEpoch 50/100\n11982/11982 [==============================] - 1s 106us/step - loss: 28971.2514 - accuracy: 8.3459e-05\nEpoch 51/100\n11982/11982 [==============================] - 1s 101us/step - loss: 28963.0965 - accuracy: 8.3459e-05\nEpoch 52/100\n11982/11982 [==============================] - 1s 95us/step - loss: 28310.0715 - accuracy: 0.0000e+00\nEpoch 53/100\n11982/11982 [==============================] - 1s 77us/step - loss: 28114.0983 - accuracy: 0.0000e+00\nEpoch 54/100\n11982/11982 [==============================] - 1s 63us/step - loss: 26678.8513 - accuracy: 1.6692e-04\nEpoch 55/100\n11982/11982 [==============================] - 1s 102us/step - loss: 27383.9762 - accuracy: 0.0000e+00\nEpoch 56/100\n11982/11982 [==============================] - 1s 100us/step - loss: 26731.8867 - accuracy: 0.0000e+00\nEpoch 57/100\n11982/11982 [==============================] - 1s 101us/step - loss: 26637.7622 - accuracy: 0.0000e+00\nEpoch 58/100\n11982/11982 [==============================] - 1s 99us/step - loss: 26115.7670 - accuracy: 0.0000e+00\nEpoch 59/100\n11982/11982 [==============================] - 1s 98us/step - loss: 25802.9740 - accuracy: 8.3459e-05\nEpoch 60/100\n11982/11982 [==============================] - 1s 93us/step - loss: 27288.1147 - accuracy: 8.3459e-05\nEpoch 61/100\n11982/11982 [==============================] - 1s 62us/step - loss: 25863.8226 - accuracy: 0.0000e+00\nEpoch 62/100\n11982/11982 [==============================] - 1s 84us/step - loss: 25572.0959 - accuracy: 0.0000e+00\nEpoch 63/100\n11982/11982 [==============================] - 1s 95us/step - loss: 24741.2712 - accuracy: 8.3459e-05\nEpoch 64/100\n11982/11982 [==============================] - 1s 103us/step - loss: 24115.1431 - accuracy: 0.0000e+00\nEpoch 65/100\n11982/11982 [==============================] - 1s 102us/step - loss: 23957.0776 - accuracy: 8.3459e-05\nEpoch 66/100\n11982/11982 [==============================] - 1s 95us/step - loss: 24501.4529 - accuracy: 8.3459e-05\nEpoch 67/100\n11982/11982 [==============================] - 1s 97us/step - loss: 23892.3276 - accuracy: 8.3459e-05\nEpoch 68/100\n11982/11982 [==============================] - 1s 81us/step - loss: 23799.6902 - accuracy: 1.6692e-04\nEpoch 69/100\n11982/11982 [==============================] - 1s 69us/step - loss: 24055.5900 - accuracy: 0.0000e+00\nEpoch 70/100\n11982/11982 [==============================] - 1s 105us/step - loss: 23409.8108 - accuracy: 0.0000e+00\nEpoch 71/100\n11982/11982 [==============================] - 1s 99us/step - loss: 24699.5147 - accuracy: 8.3459e-05\nEpoch 72/100\n11982/11982 [==============================] - 1s 97us/step - loss: 23441.8002 - accuracy: 1.6692e-04\nEpoch 73/100\n11982/11982 [==============================] - 1s 106us/step - loss: 23526.3323 - accuracy: 8.3459e-05\nEpoch 74/100\n11982/11982 [==============================] - 1s 103us/step - loss: 24044.8571 - accuracy: 1.6692e-04\nEpoch 75/100\n11982/11982 [==============================] - 1s 93us/step - loss: 22663.1680 - accuracy: 8.3459e-05\nEpoch 76/100\n11982/11982 [==============================] - 1s 69us/step - loss: 23394.4895 - accuracy: 8.3459e-05\nEpoch 77/100\n11982/11982 [==============================] - 1s 92us/step - loss: 22844.2145 - accuracy: 0.0000e+00\nEpoch 78/100\n11982/11982 [==============================] - 1s 94us/step - loss: 21982.6177 - accuracy: 0.0000e+00\nEpoch 79/100\n11982/11982 [==============================] - 1s 103us/step - loss: 23294.4525 - accuracy: 1.6692e-04\nEpoch 80/100\n11982/11982 [==============================] - 1s 104us/step - loss: 23508.9676 - accuracy: 1.6692e-04\nEpoch 81/100\n11982/11982 [==============================] - 1s 104us/step - loss: 23192.7083 - accuracy: 0.0000e+00\nEpoch 82/100\n11982/11982 [==============================] - 1s 95us/step - loss: 22933.7210 - accuracy: 1.6692e-04\nEpoch 83/100\n11982/11982 [==============================] - 1s 77us/step - loss: 22367.2109 - accuracy: 8.3459e-05\nEpoch 84/100\n11982/11982 [==============================] - 1s 72us/step - loss: 22033.9512 - accuracy: 0.0000e+00\nEpoch 85/100\n11982/11982 [==============================] - 1s 102us/step - loss: 22803.2542 - accuracy: 1.6692e-04\nEpoch 86/100\n11982/11982 [==============================] - 1s 100us/step - loss: 22233.9357 - accuracy: 0.0000e+00\nEpoch 87/100\n11982/11982 [==============================] - 1s 101us/step - loss: 22065.0325 - accuracy: 0.0000e+00\nEpoch 88/100\n11982/11982 [==============================] - 1s 101us/step - loss: 21924.0378 - accuracy: 8.3459e-05\nEpoch 89/100\n11982/11982 [==============================] - 1s 101us/step - loss: 22301.6900 - accuracy: 8.3459e-05\nEpoch 90/100\n11982/11982 [==============================] - 1s 84us/step - loss: 22466.3214 - accuracy: 0.0000e+00\nEpoch 91/100\n11982/11982 [==============================] - 1s 62us/step - loss: 21841.3002 - accuracy: 8.3459e-05\nEpoch 92/100\n11982/11982 [==============================] - 1s 96us/step - loss: 21205.6726 - accuracy: 2.5038e-04\nEpoch 93/100\n11982/11982 [==============================] - 1s 98us/step - loss: 24014.2241 - accuracy: 8.3459e-05\nEpoch 94/100\n11982/11982 [==============================] - 1s 100us/step - loss: 23157.6103 - accuracy: 8.3459e-05\nEpoch 95/100\n11982/11982 [==============================] - 1s 103us/step - loss: 21982.6086 - accuracy: 0.0000e+00\nEpoch 96/100\n11982/11982 [==============================] - 1s 108us/step - loss: 21620.0314 - accuracy: 1.6692e-04\nEpoch 97/100\n11982/11982 [==============================] - 1s 93us/step - loss: 21925.0632 - accuracy: 1.6692e-04\nEpoch 98/100\n11982/11982 [==============================] - 1s 65us/step - loss: 22192.4896 - accuracy: 8.3459e-05\nEpoch 99/100\n11982/11982 [==============================] - 1s 90us/step - loss: 21292.8694 - accuracy: 8.3459e-05\nEpoch 100/100\n11982/11982 [==============================] - 1s 101us/step - loss: 21561.7766 - accuracy: 8.3459e-05\n974/974 [==============================] - 0s 79us/step\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[5477.76802003457, 0.0]"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model_w = Sequential()\n",
    "model_w.add(Dense(output_dim=100,init='uniform',activation='relu',input_dim=15))\n",
    "model_w.add(Dense(output_dim=100,init='uniform',activation='relu'))\n",
    "model_w.add(Dense(output_dim=100,init='uniform',activation='relu'))\n",
    "model_w.add(Dense(output_dim=1,init='uniform',activation='linear'))\n",
    "\n",
    "model_w.compile(optimizer=\"adam\", loss=\"mean_squared_error\",metrics=['accuracy'])\n",
    "model_w.fit(x_train_w, y_train_w, epochs=100)\n",
    "model_w.evaluate(x_train_test_w,y_train_test_w)\n",
    "\n",
    "model_o = Sequential()\n",
    "model_o.add(Dense(output_dim=100,init='uniform',activation='relu',input_dim=14))\n",
    "model_o.add(Dense(output_dim=100,init='uniform',activation='relu'))\n",
    "model_o.add(Dense(output_dim=100,init='uniform',activation='relu'))\n",
    "model_o.add(Dense(output_dim=1,init='uniform',activation='linear'))\n",
    "\n",
    "model_o.compile(optimizer=\"adam\", loss=\"mean_squared_error\",metrics=['accuracy'])\n",
    "model_o.fit(x_train_o, y_train_o, epochs=100)\n",
    "model_o.evaluate(x_train_test_o,y_train_test_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[32.456654]\n"
    }
   ],
   "source": [
    "y_pred = []\n",
    "for x in x_test:\n",
    "    if x[-1] == 1:\n",
    "        p = x[:-1]\n",
    "        p = np.array(p).reshape(1,-1)\n",
    "        p = sc_o.transform(p)\n",
    "        y_pred.append(model_o.predict(p))\n",
    "    else:\n",
    "        p = x\n",
    "        p = np.array(p).reshape(1,-1)\n",
    "        p = sc_w.transform(p)\n",
    "        y_pred.append(model_w.predict(p))\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred[i] = y_pred[i][0]\n",
    "\n",
    "print(y_pred[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('predictions.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"gift_id\", \"price\"])\n",
    "    for i in range(len(y_pred)):\n",
    "            writer.writerow([ids[i], y_pred[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bita20695a0f1934d6e838a2f3b1d35400d",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}