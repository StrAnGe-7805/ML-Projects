{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(date):\n",
    "    papi = [datetime(int(i[:4]),int(i[5:7]),int(i[8:10]),int(i[11:13]),int(i[14:16]),int(i[17:19])) for i in date]\n",
    "    papi = [(i - min(papi)).total_seconds() for i in papi]\n",
    "    papi = [i/max(papi) for i in papi]\n",
    "    return papi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "df['instock_date'] = get_date(df['instock_date'].values)\n",
    "df['stock_update_date'] = get_date(df['stock_update_date'].values)\n",
    "df['uk_date1'] = get_date(df['uk_date1'].values)\n",
    "df['uk_date2'] = get_date(df['uk_date2'].values)\n",
    "df_test['instock_date'] = get_date(df_test['instock_date'].values)\n",
    "df_test['stock_update_date'] = get_date(df_test['stock_update_date'].values)\n",
    "df_test['uk_date1'] = get_date(df_test['uk_date1'].values)\n",
    "df_test['uk_date2'] = get_date(df_test['uk_date2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['volumes'].fillna(1, inplace=True)\n",
    "df_test['volumes'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "20279 13519\n33798\n"
    }
   ],
   "source": [
    "po = df.iloc[:,1].values\n",
    "po_t = df_test.iloc[:,1].values\n",
    "print(len(po),len(po_t))\n",
    "po = np.append(arr=po,values=po_t)\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('gift_type.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"gift_type\"])\n",
    "    for i in range(len(po)):\n",
    "            writer.writerow([po[i]])\n",
    "\n",
    "gift_type = pd.read_csv('gift_type.csv')\n",
    "k = pd.get_dummies(gift_type['gift_type'])\n",
    "k = k.values\n",
    "print(len(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.iloc[:-1000,3:-2].values\n",
    "y_train = df.iloc[:-1000,-1].values\n",
    "x_train_test = df.iloc[-1000:,3:-2].values\n",
    "y_train_test = df.iloc[-1000:,-1].values\n",
    "x_test = df_test.iloc[:,3:-1].values\n",
    "ids = df_test.iloc[:,0]\n",
    "volumes = df.iloc[:-1000,-2].values\n",
    "volumes_t = df.iloc[-1000:,-2].values\n",
    "volumes_te = df_test.iloc[:,-2].values\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i] = y_train[i]/volumes[i]\n",
    "\n",
    "for i in range(len(y_train_test)):\n",
    "    y_train[i] = y_train[i]/volumes_t[i]\n",
    "\n",
    "x_train = np.append(arr=x_train,values=k[:-14519],axis=1)\n",
    "x_train_test = np.append(arr=x_train_test,values=k[-14519:-13519],axis=1)\n",
    "x_test = np.append(arr=x_test,values=k[-13519:],axis=1)\n",
    "\n",
    "x_train_w = []\n",
    "y_train_w = []\n",
    "x_train_test_w = []\n",
    "y_train_test_w = []\n",
    "\n",
    "x_train_o = []\n",
    "y_train_o = []\n",
    "x_train_test_o = []\n",
    "y_train_test_o = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    if(volumes[i] == 1):\n",
    "        x_train_o.append(x_train[i][:-1])\n",
    "        y_train_o.append(y_train[i])\n",
    "    else:\n",
    "        x_train_w.append(x_train[i])\n",
    "        y_train_w.append(y_train[i])\n",
    "\n",
    "for i in range(len(x_train_test)):\n",
    "    if(volumes_t[i] == 1):\n",
    "        x_train_test_o.append(x_train_test[i][:-1])\n",
    "        y_train_test_o.append(y_train_test[i])\n",
    "    else:\n",
    "        x_train_test_w.append(x_train_test[i])\n",
    "        y_train_test_w.append(y_train_test[i])\n",
    "\n",
    "x_train_w = np.array(x_train_w)\n",
    "x_train_o = np.array(x_train_o)\n",
    "y_train_w = np.array(y_train_w)\n",
    "y_train_o = np.array(y_train_o)\n",
    "x_train_test_w = np.array(x_train_test_w)\n",
    "x_train_test_o = np.array(x_train_test_o)\n",
    "y_train_test_w = np.array(y_train_test_w)\n",
    "y_train_test_o = np.array(y_train_test_o)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_w = StandardScaler()\n",
    "x_train_w = sc_w.fit_transform(x_train_w)\n",
    "x_train_test_w = sc_w.transform(x_train_test_w)\n",
    "\n",
    "sc_o = StandardScaler()\n",
    "x_train_o = sc_o.fit_transform(x_train_o)\n",
    "x_train_test_o = sc_o.transform(x_train_test_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1373 1373 1373\n"
    }
   ],
   "source": [
    "print(len(x_train_test[100]),len(x_test[2000]),len(x_train[450]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "us/step - loss: 0.2146 - accuracy: 1.3704e-04\nEpoch 26/100\n7297/7297 [==============================] - 2s 240us/step - loss: 0.1943 - accuracy: 2.7409e-04\nEpoch 27/100\n7297/7297 [==============================] - 2s 219us/step - loss: 0.1996 - accuracy: 1.3704e-04\nEpoch 28/100\n7297/7297 [==============================] - 2s 228us/step - loss: 0.1895 - accuracy: 2.7409e-04\nEpoch 29/100\n7297/7297 [==============================] - 2s 238us/step - loss: 0.2003 - accuracy: 2.7409e-04\nEpoch 30/100\n7297/7297 [==============================] - 2s 213us/step - loss: 0.1832 - accuracy: 1.3704e-04\nEpoch 31/100\n7297/7297 [==============================] - 1s 175us/step - loss: 0.1955 - accuracy: 1.3704e-04\nEpoch 32/100\n7297/7297 [==============================] - 2s 212us/step - loss: 0.1782 - accuracy: 1.3704e-04\nEpoch 33/100\n7297/7297 [==============================] - 2s 254us/step - loss: 0.1906 - accuracy: 1.3704e-04\nEpoch 34/100\n7297/7297 [==============================] - 2s 234us/step - loss: 0.1763 - accuracy: 1.3704e-04\nEpoch 35/100\n7297/7297 [==============================] - 2s 251us/step - loss: 0.1754 - accuracy: 1.3704e-04\nEpoch 36/100\n7297/7297 [==============================] - 2s 250us/step - loss: 0.1766 - accuracy: 2.7409e-04\nEpoch 37/100\n7297/7297 [==============================] - 2s 224us/step - loss: 0.1703 - accuracy: 1.3704e-04\nEpoch 38/100\n7297/7297 [==============================] - 2s 234us/step - loss: 0.1828 - accuracy: 2.7409e-04\nEpoch 39/100\n7297/7297 [==============================] - 2s 237us/step - loss: 0.1709 - accuracy: 1.3704e-04\nEpoch 40/100\n7297/7297 [==============================] - 2s 244us/step - loss: 0.1728 - accuracy: 1.3704e-04\nEpoch 41/100\n7297/7297 [==============================] - 2s 242us/step - loss: 0.1755 - accuracy: 2.7409e-04\nEpoch 42/100\n7297/7297 [==============================] - 2s 223us/step - loss: 0.1670 - accuracy: 1.3704e-04\nEpoch 43/100\n7297/7297 [==============================] - 2s 228us/step - loss: 0.1686 - accuracy: 1.3704e-04\nEpoch 44/100\n7297/7297 [==============================] - 2s 217us/step - loss: 0.1655 - accuracy: 2.7409e-04\nEpoch 45/100\n7297/7297 [==============================] - 2s 229us/step - loss: 0.1725 - accuracy: 2.7409e-04\nEpoch 46/100\n7297/7297 [==============================] - 2s 226us/step - loss: 0.1584 - accuracy: 2.7409e-04\nEpoch 47/100\n7297/7297 [==============================] - 2s 225us/step - loss: 0.1595 - accuracy: 1.3704e-04\nEpoch 48/100\n7297/7297 [==============================] - 2s 221us/step - loss: 0.1596 - accuracy: 1.3704e-04\nEpoch 49/100\n7297/7297 [==============================] - 2s 212us/step - loss: 0.1578 - accuracy: 0.0000e+00\nEpoch 50/100\n7297/7297 [==============================] - 1s 155us/step - loss: 0.1570 - accuracy: 2.7409e-04\nEpoch 51/100\n7297/7297 [==============================] - 2s 213us/step - loss: 0.1545 - accuracy: 1.3704e-04\nEpoch 52/100\n7297/7297 [==============================] - 2s 226us/step - loss: 0.1553 - accuracy: 1.3704e-04\nEpoch 53/100\n7297/7297 [==============================] - 2s 224us/step - loss: 0.1580 - accuracy: 2.7409e-04\nEpoch 54/100\n7297/7297 [==============================] - 2s 231us/step - loss: 0.1569 - accuracy: 1.3704e-04\nEpoch 55/100\n7297/7297 [==============================] - 2s 241us/step - loss: 0.1516 - accuracy: 1.3704e-04\nEpoch 56/100\n7297/7297 [==============================] - 2s 240us/step - loss: 0.1499 - accuracy: 2.7409e-04\nEpoch 57/100\n7297/7297 [==============================] - 2s 225us/step - loss: 0.1483 - accuracy: 1.3704e-04\nEpoch 58/100\n7297/7297 [==============================] - 2s 224us/step - loss: 0.1495 - accuracy: 2.7409e-04\nEpoch 59/100\n7297/7297 [==============================] - 2s 225us/step - loss: 0.1475 - accuracy: 2.7409e-04\nEpoch 60/100\n7297/7297 [==============================] - 2s 217us/step - loss: 0.1525 - accuracy: 2.7409e-04\nEpoch 61/100\n7297/7297 [==============================] - 2s 210us/step - loss: 0.1516 - accuracy: 1.3704e-04\nEpoch 62/100\n7297/7297 [==============================] - 1s 205us/step - loss: 0.1506 - accuracy: 0.0000e+00\nEpoch 63/100\n7297/7297 [==============================] - 2s 225us/step - loss: 0.1449 - accuracy: 2.7409e-04\nEpoch 64/100\n7297/7297 [==============================] - 2s 224us/step - loss: 0.1429 - accuracy: 2.7409e-04\nEpoch 65/100\n7297/7297 [==============================] - 2s 219us/step - loss: 0.1492 - accuracy: 2.7409e-04\nEpoch 66/100\n7297/7297 [==============================] - 2s 217us/step - loss: 0.1421 - accuracy: 2.7409e-04\nEpoch 67/100\n7297/7297 [==============================] - 2s 217us/step - loss: 0.1394 - accuracy: 2.7409e-04\nEpoch 68/100\n7297/7297 [==============================] - 2s 227us/step - loss: 0.1382 - accuracy: 2.7409e-04\nEpoch 69/100\n7297/7297 [==============================] - 2s 226us/step - loss: 0.1402 - accuracy: 2.7409e-04\nEpoch 70/100\n7297/7297 [==============================] - 2s 221us/step - loss: 0.1454 - accuracy: 1.3704e-04\nEpoch 71/100\n7297/7297 [==============================] - 1s 167us/step - loss: 0.1446 - accuracy: 2.7409e-04\nEpoch 72/100\n7297/7297 [==============================] - 1s 162us/step - loss: 0.1421 - accuracy: 1.3704e-04\nEpoch 73/100\n7297/7297 [==============================] - 2s 243us/step - loss: 0.1361 - accuracy: 1.3704e-04\nEpoch 74/100\n7297/7297 [==============================] - 2s 222us/step - loss: 0.1391 - accuracy: 2.7409e-04\nEpoch 75/100\n7297/7297 [==============================] - 2s 220us/step - loss: 0.1454 - accuracy: 2.7409e-04\nEpoch 76/100\n7297/7297 [==============================] - 2s 218us/step - loss: 0.1393 - accuracy: 1.3704e-04\nEpoch 77/100\n7297/7297 [==============================] - 2s 236us/step - loss: 0.1341 - accuracy: 2.7409e-04\nEpoch 78/100\n7297/7297 [==============================] - 2s 246us/step - loss: 0.1353 - accuracy: 2.7409e-04\nEpoch 79/100\n7297/7297 [==============================] - 2s 242us/step - loss: 0.1337 - accuracy: 1.3704e-04\nEpoch 80/100\n7297/7297 [==============================] - 2s 220us/step - loss: 0.1349 - accuracy: 2.7409e-04\nEpoch 81/100\n7297/7297 [==============================] - 2s 237us/step - loss: 0.1343 - accuracy: 1.3704e-04\nEpoch 82/100\n7297/7297 [==============================] - 2s 232us/step - loss: 0.1326 - accuracy: 2.7409e-04\nEpoch 83/100\n7297/7297 [==============================] - 2s 226us/step - loss: 0.1392 - accuracy: 1.3704e-04\nEpoch 84/100\n7297/7297 [==============================] - 2s 225us/step - loss: 0.1356 - accuracy: 2.7409e-04\nEpoch 85/100\n7297/7297 [==============================] - 2s 211us/step - loss: 0.1313 - accuracy: 2.7409e-04\nEpoch 86/100\n7297/7297 [==============================] - 2s 223us/step - loss: 0.1308 - accuracy: 2.7409e-04\nEpoch 87/100\n7297/7297 [==============================] - 2s 230us/step - loss: 0.1319 - accuracy: 2.7409e-04\nEpoch 88/100\n7297/7297 [==============================] - 2s 229us/step - loss: 0.1316 - accuracy: 2.7409e-04\nEpoch 89/100\n7297/7297 [==============================] - 2s 215us/step - loss: 0.1323 - accuracy: 1.3704e-04\nEpoch 90/100\n7297/7297 [==============================] - 2s 219us/step - loss: 0.1295 - accuracy: 2.7409e-04\nEpoch 91/100\n7297/7297 [==============================] - 2s 222us/step - loss: 0.1303 - accuracy: 1.3704e-04\nEpoch 92/100\n7297/7297 [==============================] - 2s 218us/step - loss: 0.1334 - accuracy: 2.7409e-04\nEpoch 93/100\n7297/7297 [==============================] - 2s 220us/step - loss: 0.1300 - accuracy: 2.7409e-04\nEpoch 94/100\n7297/7297 [==============================] - 2s 225us/step - loss: 0.1349 - accuracy: 1.3704e-04\nEpoch 95/100\n7297/7297 [==============================] - 2s 218us/step - loss: 0.1355 - accuracy: 2.7409e-04\nEpoch 96/100\n7297/7297 [==============================] - 2s 227us/step - loss: 0.1267 - accuracy: 1.3704e-04\nEpoch 97/100\n7297/7297 [==============================] - 1s 166us/step - loss: 0.1281 - accuracy: 2.7409e-04\nEpoch 98/100\n7297/7297 [==============================] - 1s 190us/step - loss: 0.1297 - accuracy: 2.7409e-04\nEpoch 99/100\n7297/7297 [==============================] - 2s 228us/step - loss: 0.1411 - accuracy: 1.3704e-04\nEpoch 100/100\n7297/7297 [==============================] - 2s 217us/step - loss: 0.1244 - accuracy: 1.3704e-04\n26/26 [==============================] - 0s 2ms/step\nEpoch 1/100\n11982/11982 [==============================] - 3s 256us/step - loss: 68731.6979 - accuracy: 0.0000e+00\nEpoch 2/100\n11982/11982 [==============================] - 3s 221us/step - loss: 45142.1587 - accuracy: 8.3459e-05\nEpoch 3/100\n11982/11982 [==============================] - 3s 229us/step - loss: 38150.0292 - accuracy: 8.3459e-05\nEpoch 4/100\n11982/11982 [==============================] - 3s 225us/step - loss: 35621.5895 - accuracy: 8.3459e-05\nEpoch 5/100\n11982/11982 [==============================] - 3s 232us/step - loss: 32138.6257 - accuracy: 1.6692e-04\nEpoch 6/100\n11982/11982 [==============================] - 3s 234us/step - loss: 30918.2549 - accuracy: 1.6692e-04\nEpoch 7/100\n11982/11982 [==============================] - 3s 229us/step - loss: 29926.9554 - accuracy: 8.3459e-05\nEpoch 8/100\n11982/11982 [==============================] - 3s 229us/step - loss: 29284.3123 - accuracy: 1.6692e-04\nEpoch 9/100\n11982/11982 [==============================] - 3s 223us/step - loss: 28746.7766 - accuracy: 2.5038e-04\nEpoch 10/100\n11982/11982 [==============================] - 2s 186us/step - loss: 28641.9120 - accuracy: 2.5038e-04\nEpoch 11/100\n11982/11982 [==============================] - 2s 203us/step - loss: 28418.2031 - accuracy: 2.5038e-04\nEpoch 12/100\n11982/11982 [==============================] - 3s 235us/step - loss: 28216.4658 - accuracy: 1.6692e-04\nEpoch 13/100\n11982/11982 [==============================] - 3s 230us/step - loss: 28097.0690 - accuracy: 1.6692e-04\nEpoch 14/100\n11982/11982 [==============================] - 3s 229us/step - loss: 28322.6638 - accuracy: 8.3459e-05\nEpoch 15/100\n11982/11982 [==============================] - 3s 232us/step - loss: 28019.2209 - accuracy: 2.5038e-04\nEpoch 16/100\n11982/11982 [==============================] - 3s 231us/step - loss: 27952.0786 - accuracy: 0.0000e+00\nEpoch 17/100\n11982/11982 [==============================] - 3s 226us/step - loss: 27701.0245 - accuracy: 8.3459e-05\nEpoch 18/100\n11982/11982 [==============================] - 3s 229us/step - loss: 27374.7197 - accuracy: 0.0000e+00\nEpoch 19/100\n11982/11982 [==============================] - 3s 230us/step - loss: 27386.3705 - accuracy: 0.0000e+00\nEpoch 20/100\n11982/11982 [==============================] - 3s 221us/step - loss: 27260.0142 - accuracy: 3.3383e-04\nEpoch 21/100\n11982/11982 [==============================] - 3s 229us/step - loss: 27459.8253 - accuracy: 1.6692e-04\nEpoch 22/100\n11982/11982 [==============================] - 3s 228us/step - loss: 27426.1810 - accuracy: 1.6692e-04\nEpoch 23/100\n11982/11982 [==============================] - 2s 191us/step - loss: 27133.9064 - accuracy: 2.5038e-04\nEpoch 24/100\n11982/11982 [==============================] - 2s 185us/step - loss: 27048.4654 - accuracy: 8.3459e-05\nEpoch 25/100\n11982/11982 [==============================] - 3s 230us/step - loss: 26772.4803 - accuracy: 0.0000e+00\nEpoch 26/100\n11982/11982 [==============================] - 3s 228us/step - loss: 26980.8580 - accuracy: 0.0000e+00\nEpoch 27/100\n11982/11982 [==============================] - 3s 231us/step - loss: 26684.2073 - accuracy: 0.0000e+00\nEpoch 28/100\n11982/11982 [==============================] - 3s 217us/step - loss: 26773.3494 - accuracy: 1.6692e-04\nEpoch 29/100\n11982/11982 [==============================] - 3s 226us/step - loss: 26387.6479 - accuracy: 1.6692e-04\nEpoch 30/100\n11982/11982 [==============================] - 3s 221us/step - loss: 26762.0563 - accuracy: 8.3459e-05\nEpoch 31/100\n11982/11982 [==============================] - 3s 235us/step - loss: 27010.7950 - accuracy: 8.3459e-05\nEpoch 32/100\n11982/11982 [==============================] - 3s 224us/step - loss: 26610.3561 - accuracy: 1.6692e-04\nEpoch 33/100\n11982/11982 [==============================] - 3s 225us/step - loss: 26168.8617 - accuracy: 8.3459e-05\nEpoch 34/100\n11982/11982 [==============================] - 3s 233us/step - loss: 26179.5143 - accuracy: 3.3383e-04\nEpoch 35/100\n11982/11982 [==============================] - 3s 222us/step - loss: 26035.4417 - accuracy: 1.6692e-04\nEpoch 36/100\n11982/11982 [==============================] - 2s 175us/step - loss: 25647.1928 - accuracy: 1.6692e-04\nEpoch 37/100\n11982/11982 [==============================] - 3s 227us/step - loss: 25613.2694 - accuracy: 0.0000e+00\nEpoch 38/100\n11982/11982 [==============================] - 3s 216us/step - loss: 25557.3606 - accuracy: 3.3383e-04\nEpoch 39/100\n11982/11982 [==============================] - 3s 220us/step - loss: 25791.7118 - accuracy: 4.1729e-04\nEpoch 40/100\n11982/11982 [==============================] - 3s 229us/step - loss: 25805.9122 - accuracy: 8.3459e-05\nEpoch 41/100\n11982/11982 [==============================] - 3s 213us/step - loss: 25485.7408 - accuracy: 8.3459e-05\nEpoch 42/100\n11982/11982 [==============================] - 3s 212us/step - loss: 25110.6474 - accuracy: 2.5038e-04\nEpoch 43/100\n11982/11982 [==============================] - 3s 216us/step - loss: 24858.6741 - accuracy: 8.3459e-05\nEpoch 44/100\n11982/11982 [==============================] - 3s 211us/step - loss: 25030.3512 - accuracy: 1.6692e-04\nEpoch 45/100\n11982/11982 [==============================] - 3s 210us/step - loss: 24721.1925 - accuracy: 0.0000e+00\nEpoch 46/100\n11982/11982 [==============================] - 3s 212us/step - loss: 24456.1369 - accuracy: 8.3459e-05\nEpoch 47/100\n11982/11982 [==============================] - 2s 199us/step - loss: 24235.4435 - accuracy: 8.3459e-05\nEpoch 48/100\n11982/11982 [==============================] - 2s 176us/step - loss: 24222.9470 - accuracy: 2.5038e-04\nEpoch 49/100\n11982/11982 [==============================] - 3s 219us/step - loss: 24077.4781 - accuracy: 2.5038e-04\nEpoch 50/100\n11982/11982 [==============================] - 3s 225us/step - loss: 23890.2907 - accuracy: 4.1729e-04\nEpoch 51/100\n11982/11982 [==============================] - 3s 216us/step - loss: 22974.2623 - accuracy: 1.6692e-04\nEpoch 52/100\n11982/11982 [==============================] - 3s 221us/step - loss: 23250.2539 - accuracy: 0.0000e+00\nEpoch 53/100\n11982/11982 [==============================] - 658s 55ms/step - loss: 23557.3262 - accuracy: 8.3459e-05\nEpoch 54/100\n11982/11982 [==============================] - 2s 203us/step - loss: 22694.7463 - accuracy: 4.1729e-04\nEpoch 55/100\n11982/11982 [==============================] - 4s 334us/step - loss: 22455.0577 - accuracy: 1.6692e-04\nEpoch 56/100\n11982/11982 [==============================] - 3s 252us/step - loss: 22314.1578 - accuracy: 2.5038e-04\nEpoch 57/100\n11982/11982 [==============================] - 3s 243us/step - loss: 22299.6349 - accuracy: 1.6692e-04\nEpoch 58/100\n11982/11982 [==============================] - 3s 248us/step - loss: 22278.1838 - accuracy: 2.5038e-04\nEpoch 59/100\n11982/11982 [==============================] - 3s 231us/step - loss: 21708.6832 - accuracy: 4.1729e-04\nEpoch 60/100\n11982/11982 [==============================] - 3s 235us/step - loss: 21654.7826 - accuracy: 1.6692e-04\nEpoch 61/100\n11982/11982 [==============================] - 2s 200us/step - loss: 21449.7693 - accuracy: 1.6692e-04\nEpoch 62/100\n11982/11982 [==============================] - 2s 194us/step - loss: 21092.0818 - accuracy: 8.3459e-05\nEpoch 63/100\n11982/11982 [==============================] - 3s 235us/step - loss: 21176.7952 - accuracy: 2.5038e-04\nEpoch 64/100\n11982/11982 [==============================] - 3s 236us/step - loss: 21011.4945 - accuracy: 4.1729e-04\nEpoch 65/100\n11982/11982 [==============================] - 3s 230us/step - loss: 20690.1453 - accuracy: 8.3459e-05\nEpoch 66/100\n11982/11982 [==============================] - 3s 232us/step - loss: 20563.6996 - accuracy: 1.6692e-04\nEpoch 67/100\n11982/11982 [==============================] - 3s 214us/step - loss: 20297.0566 - accuracy: 2.5038e-04\nEpoch 68/100\n11982/11982 [==============================] - 2s 173us/step - loss: 20261.7052 - accuracy: 3.3383e-04\nEpoch 69/100\n11982/11982 [==============================] - 3s 221us/step - loss: 19733.3779 - accuracy: 1.6692e-04\nEpoch 70/100\n11982/11982 [==============================] - 3s 227us/step - loss: 19383.3282 - accuracy: 2.5038e-04\nEpoch 71/100\n11982/11982 [==============================] - 3s 220us/step - loss: 20122.9888 - accuracy: 2.5038e-04\nEpoch 72/100\n11982/11982 [==============================] - 3s 246us/step - loss: 19679.8670 - accuracy: 8.3459e-05\nEpoch 73/100\n11982/11982 [==============================] - 3s 235us/step - loss: 19025.6336 - accuracy: 3.3383e-04\nEpoch 74/100\n11982/11982 [==============================] - 3s 240us/step - loss: 19253.8087 - accuracy: 8.3459e-05\nEpoch 75/100\n11982/11982 [==============================] - 3s 237us/step - loss: 18830.1393 - accuracy: 5.0075e-04\nEpoch 76/100\n11982/11982 [==============================] - 3s 224us/step - loss: 19027.2054 - accuracy: 1.6692e-04\nEpoch 77/100\n11982/11982 [==============================] - 3s 234us/step - loss: 18390.7856 - accuracy: 4.1729e-04\nEpoch 78/100\n11982/11982 [==============================] - 3s 223us/step - loss: 18133.7162 - accuracy: 4.1729e-04\nEpoch 79/100\n11982/11982 [==============================] - 2s 194us/step - loss: 18454.9678 - accuracy: 1.6692e-04\nEpoch 80/100\n11982/11982 [==============================] - 2s 178us/step - loss: 17841.8536 - accuracy: 1.6692e-04\nEpoch 81/100\n11982/11982 [==============================] - 3s 226us/step - loss: 17592.9406 - accuracy: 5.8421e-04\nEpoch 82/100\n11982/11982 [==============================] - 3s 228us/step - loss: 17556.6282 - accuracy: 4.1729e-04\nEpoch 83/100\n11982/11982 [==============================] - 3s 224us/step - loss: 17203.7512 - accuracy: 5.0075e-04\nEpoch 84/100\n11982/11982 [==============================] - 3s 227us/step - loss: 17910.8688 - accuracy: 2.5038e-04\nEpoch 85/100\n11982/11982 [==============================] - 3s 229us/step - loss: 16277.8142 - accuracy: 4.1729e-04\nEpoch 86/100\n11982/11982 [==============================] - 3s 225us/step - loss: 17714.3459 - accuracy: 3.3383e-04\nEpoch 87/100\n11982/11982 [==============================] - 3s 225us/step - loss: 16411.7771 - accuracy: 5.0075e-04\nEpoch 88/100\n11982/11982 [==============================] - 3s 231us/step - loss: 16857.0629 - accuracy: 3.3383e-04\nEpoch 89/100\n11982/11982 [==============================] - 3s 213us/step - loss: 16808.5718 - accuracy: 1.6692e-04\nEpoch 90/100\n11982/11982 [==============================] - 2s 168us/step - loss: 16459.6351 - accuracy: 3.3383e-04\nEpoch 91/100\n11982/11982 [==============================] - 3s 222us/step - loss: 16850.3615 - accuracy: 8.3459e-05\nEpoch 92/100\n11982/11982 [==============================] - 3s 216us/step - loss: 16155.5279 - accuracy: 3.3383e-04\nEpoch 93/100\n11982/11982 [==============================] - 3s 226us/step - loss: 16126.2701 - accuracy: 2.5038e-04\nEpoch 94/100\n11982/11982 [==============================] - 3s 220us/step - loss: 16066.6002 - accuracy: 4.1729e-04\nEpoch 95/100\n11982/11982 [==============================] - 3s 216us/step - loss: 15653.1182 - accuracy: 8.3459e-05\nEpoch 96/100\n11982/11982 [==============================] - 3s 215us/step - loss: 15920.3279 - accuracy: 5.0075e-04\nEpoch 97/100\n11982/11982 [==============================] - 3s 221us/step - loss: 15370.5346 - accuracy: 2.5038e-04\nEpoch 98/100\n11982/11982 [==============================] - 2s 205us/step - loss: 15423.9674 - accuracy: 8.3459e-05\nEpoch 99/100\n11982/11982 [==============================] - 2s 172us/step - loss: 15645.1533 - accuracy: 8.3459e-05\nEpoch 100/100\n11982/11982 [==============================] - 3s 222us/step - loss: 15698.3281 - accuracy: 2.5038e-04\n974/974 [==============================] - 0s 125us/step\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[7318.249150771625, 0.0]"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model_w = Sequential()\n",
    "model_w.add(Dense(output_dim=100,init='uniform',activation='relu',input_dim=1373))\n",
    "model_w.add(Dense(output_dim=100,init='uniform',activation='relu'))\n",
    "model_w.add(Dense(output_dim=100,init='uniform',activation='relu'))\n",
    "model_w.add(Dense(output_dim=1,init='uniform',activation='linear'))\n",
    "\n",
    "model_w.compile(optimizer=\"adam\", loss=\"mean_squared_error\",metrics=['accuracy'])\n",
    "model_w.fit(x_train_w, y_train_w, epochs=100)\n",
    "model_w.evaluate(x_train_test_w,y_train_test_w)\n",
    "\n",
    "model_o = Sequential()\n",
    "model_o.add(Dense(output_dim=100,init='uniform',activation='relu',input_dim=1372))\n",
    "model_o.add(Dense(output_dim=100,init='uniform',activation='relu'))\n",
    "model_o.add(Dense(output_dim=100,init='uniform',activation='relu'))\n",
    "model_o.add(Dense(output_dim=1,init='uniform',activation='linear'))\n",
    "\n",
    "model_o.compile(optimizer=\"adam\", loss=\"mean_squared_error\",metrics=['accuracy'])\n",
    "model_o.fit(x_train_o, y_train_o, epochs=100)\n",
    "model_o.evaluate(x_train_test_o,y_train_test_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[2.40000000e+01]\n [0.00000000e+00]\n [2.30103579e-02]\n ...\n [0.00000000e+00]\n [0.00000000e+00]\n [0.00000000e+00]]\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1373,1) doesn't match the broadcast shape (1373,1373)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-693f8469fc72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvolumes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (1373,1) doesn't match the broadcast shape (1373,1373)"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "for i in range(len(x_test)):\n",
    "    if volumes_te[i] == 1:\n",
    "        p = x_test[i]\n",
    "        p = np.array(p).reshape(-1,1)\n",
    "        print(len(p))\n",
    "        p = sc_o.transform(p)\n",
    "        y_pred.append(model_o.predict(p))\n",
    "    else:\n",
    "        p = x_test[i]\n",
    "        p = np.array(p).reshape(-1,1)\n",
    "        print(p)\n",
    "        p = sc_w.transform(p)\n",
    "        p = model_w.predict(p)\n",
    "        p[0] = p[0]*volumes[i]\n",
    "        y_pred.append(p)\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred[i] = y_pred[i][0]\n",
    "\n",
    "print(y_pred[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('predictions5.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"gift_id\", \"price\"])\n",
    "    for i in range(len(y_pred)):\n",
    "            writer.writerow([ids[i], y_pred[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1. 1. 1. ... 1. 1. 1.]\n"
    }
   ],
   "source": [
    "volumes = df.iloc[:,-2].values\n",
    "print(volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit82a99759a9bc43759387fd87aa809f13",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}